{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5efe1c6-86dd-427c-b137-03d74d37115f",
   "metadata": {},
   "source": [
    "# Science Demonstration Case: Polar Science\n",
    "# Automatic ice damage detection from Sentinel-1 radar imagery\n",
    "## Step 2: Get Sentinel-1 imagery data.\n",
    "### For more info about this science case, please check the documentation [at this link](https://earthsystemdatalab.net/science_cases/polar_science/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73223100-2cfa-40c4-93e3-f2df37a88e46",
   "metadata": {},
   "source": [
    "In this notebook SentinelHub is exploited to query, preprocess and download Sentinel-1 data.<br>\n",
    "The imagery data is then saved into a datacube, with the same resolution and extent as the damage model.\n",
    "\n",
    "NB: A SentinelHub account is required in order to use its functionalities. By default the `sh.SHConfig()` instance will look for the `SH_CLIENT_ID` and `SH_CLIENT_SECRET` environment variables.<br>\n",
    "If they are not set, they can be passed to the `sh.SHConfig()` instance after its creation by running `sh_config.sh_client_id = <ID>` and `sh_config.sh_client_secret = <SECRET>`.\n",
    "\n",
    "**This notebook runs with the python environment `polar-science-use-case`, please checkout the documentation for [help on changing the environment](https://deepesdl.readthedocs.io/en/latest/guide/jupyterlab/#python-environment-selection-of-the-jupyter-kerne).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f99c7329-3a38-421e-b24c-57c697b7deca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import sentinelhub as sh\n",
    "import xarray as xr\n",
    "from xcube.core.store import new_data_store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cba934",
   "metadata": {},
   "source": [
    "Define the parameters needed to access the S3 storage. They are saved as environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62169dfd-4900-4af6-a935-b91d4772f834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "S3_USER_STORAGE_KEY = os.environ[\"S3_USER_STORAGE_KEY\"]\n",
    "S3_USER_STORAGE_SECRET = os.environ[\"S3_USER_STORAGE_SECRET\"]\n",
    "S3_USER_STORAGE_BUCKET = os.environ[\"S3_USER_STORAGE_BUCKET\"]\n",
    "\n",
    "team_store = new_data_store(\n",
    "    data_store_id=\"s3\",\n",
    "    root=S3_USER_STORAGE_BUCKET,\n",
    "    storage_options=dict(\n",
    "        anon=False, key=S3_USER_STORAGE_KEY,\n",
    "        secret=S3_USER_STORAGE_SECRET\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13e8c56",
   "metadata": {},
   "source": [
    "Set the directory where the Sentinel-1 scenes will be downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac170b0-9624-4ac4-8ec4-c7f349358cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "iceshelf_name = \"amery\"\n",
    "\n",
    "download_directory = Path.cwd() / \"sh_download_directory\" / iceshelf_name\n",
    "download_directory.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8e66d9",
   "metadata": {},
   "source": [
    "# Query setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7e1a5e-4080-4d0d-8fdb-e392a2386f34",
   "metadata": {},
   "source": [
    "<b>Coordinate Reference Systems</b>\n",
    "\n",
    "- EPSG 3031 is Antarctic Polar Stereographic projected coordinates\n",
    "- UTM depends on the longitude of the area of interest and is needed to specify the resolution / size of the imagery data, due to how SentinelHub is implemented\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e5b7ea-a502-42a2-9d9f-006acce4ac80",
   "metadata": {},
   "source": [
    "<b>Bounding box of the area of interest</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88473ae7-b8a6-46ec-a6df-be216d24e587",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iceshelf_bbox = sh.BBox((1566250, 533250, 2266750, 933750), crs=sh.CRS(3031))\n",
    "\n",
    "# resolution in [m], in EPSG:3031 projected coordinates\n",
    "resolution_x, resolution_y = (500, 500)\n",
    "\n",
    "# size of the imagery array given the resolution specified above\n",
    "imagery_width = round(abs(iceshelf_bbox.max_x - iceshelf_bbox.min_x) / resolution_x)\n",
    "imagery_height = round(abs(iceshelf_bbox.max_y - iceshelf_bbox.min_y) / resolution_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ad02ce-3e0a-4c57-a220-01e3a39af92f",
   "metadata": {},
   "source": [
    "<b>Time interval of interest</b>\n",
    "\n",
    "As an example, let's download the data with acquisition date within the first 5 days of October 2016.<br>\n",
    "This use case employs data from the last three months (Q4) of both 2015 and 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc04e982-7c4a-43e9-b2c0-a597b2769285",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_start = datetime(2016, 10, 1)\n",
    "time_end = datetime(2016, 10, 5)\n",
    "\n",
    "# set the time interval in the format required by the SentinelHub API\n",
    "time_interval = time_start.strftime(\"%Y-%m-%d\"), time_end.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# this is useful to distinguish the files in case data is downloaded for multiple time intervals\n",
    "time_period_label = \"test_Oct2016\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2a5388-aff0-4362-a0c7-e0461e7fd5e8",
   "metadata": {},
   "source": [
    "<b>Sentinel-1 categories</b>\n",
    "- Acquisition mode\n",
    "    - IW: Interferometric Wide swath mode\n",
    "    - EW: Extra Wide swath mode\n",
    "- Polarisation\n",
    "    - SH: only HH co-polarisation\n",
    "    - SV: only VV co-polarisation\n",
    "    - DH: double polarisation, both co- (HH) and cross- (HV)\n",
    "    - DV: double polarisation, both co- (VV) and cross- (VH)\n",
    "- Orbit\n",
    "    - Ascending\n",
    "    - Descending"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7021f532-d481-40ba-b213-09a93b038d28",
   "metadata": {},
   "source": [
    "<b>Evalscripts custom scripts</b>\n",
    "\n",
    "Sentinel-1 queries can be performed with custom Javascript scripts (also called _evalscripts_).<br>\n",
    "Check out the SentinelHub documentation at [this link](https://docs.sentinel-hub.com/api/latest/evalscript/v3/) for a thorough explanation of what the evalscripts look like and what they can be used for.\n",
    "\n",
    "What follows are the v3 evalscripts used to query Sentinel-1 data over the polar regions, where only DH and SH polarisation modes are available.<br>\n",
    "Only the latter is used in this notebook, to get all the scenes in single polarisation mode containing only co-polarised data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b07293-74ee-4df5-b7ed-97db1b556abc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this is for the scenes with double polarisation\n",
    "\n",
    "evalscript_s1_pol_dh = \"\"\"\n",
    "    //VERSION=3\n",
    "\n",
    "    function setup() {\n",
    "        return {\n",
    "            input: [{\n",
    "                bands: [\"HH\", \"HV\"]\n",
    "            }],\n",
    "            output: {\n",
    "                bands: 2, sampleType: \"FLOAT32\"\n",
    "            }\n",
    "        };\n",
    "    }\n",
    "\n",
    "    function evaluatePixel(sample) {\n",
    "        return [sample.HH, sample.HV];\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# this is for the scenes with single polarisation\n",
    "\n",
    "evalscript_s1_pol_sh = \"\"\"\n",
    "    //VERSION=3\n",
    "\n",
    "    function setup() {\n",
    "        return {\n",
    "            input: [{\n",
    "                bands: [\"HH\"]\n",
    "            }],\n",
    "            output: {\n",
    "                bands: 1, sampleType: \"FLOAT32\"\n",
    "            }\n",
    "        };\n",
    "    }\n",
    "\n",
    "    function evaluatePixel(sample) {\n",
    "        return [sample.HH];\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554eca3c-ab4e-4b6e-b2c0-a6313fb23488",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Query and download the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e297ad",
   "metadata": {},
   "source": [
    "### Find the scenes that overlap the area of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c8899f-ebea-44bd-868f-a64509fa572f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of results: 8\n"
     ]
    }
   ],
   "source": [
    "# set up the Sentinel Hub Config object\n",
    "sh_config = sh.SHConfig()\n",
    "sh_config.sh_base_url = sh.DataCollection.SENTINEL1.service_url\n",
    "sh_catalog = sh.SentinelHubCatalog(config=sh_config)\n",
    "\n",
    "# the search is performed only based on the bounding box and the time interval\n",
    "search_iterator = sh_catalog.search(\n",
    "    sh.DataCollection.SENTINEL1,\n",
    "    bbox=iceshelf_bbox,\n",
    "    time=time_interval,\n",
    "    fields={\"include\": [\"id\", \"properties.datetime\"],\n",
    "            \"exclude\": []},\n",
    ")\n",
    "results = list(search_iterator)\n",
    "print(\"Total number of results:\", len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e49901",
   "metadata": {},
   "source": [
    "Have a look at the IDs of the scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4812f52d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S1B_EW_GRDM_1SSH_20161004T152819_20161004T152923_002358_003FBD_384F',\n",
       " 'S1A_EW_GRDM_1SSH_20161004T143928_20161004T144032_013341_015466_DA25',\n",
       " 'S1A_IW_GRDH_1SSH_20161003T220432_20161003T220502_013331_015416_78EA',\n",
       " 'S1A_IW_GRDH_1SSH_20161003T220407_20161003T220432_013331_015416_12CA',\n",
       " 'S1A_IW_GRDH_1SSH_20161003T220342_20161003T220407_013331_015416_1A83',\n",
       " 'S1A_IW_GRDH_1SSH_20161003T220317_20161003T220342_013331_015416_4FF6',\n",
       " 'S1A_IW_GRDH_1SSH_20161003T220252_20161003T220317_013331_015416_47F5',\n",
       " 'S1B_EW_GRDM_1SSH_20161003T144654_20161003T144758_002343_003F5C_63D4']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_iterator.get_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70c29ec",
   "metadata": {},
   "source": [
    "And their acquisition timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e73f58bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2016, 10, 4, 15, 28, 19, tzinfo=tzutc()),\n",
       " datetime.datetime(2016, 10, 4, 14, 39, 28, tzinfo=tzutc()),\n",
       " datetime.datetime(2016, 10, 3, 22, 4, 32, tzinfo=tzutc()),\n",
       " datetime.datetime(2016, 10, 3, 22, 4, 7, tzinfo=tzutc()),\n",
       " datetime.datetime(2016, 10, 3, 22, 3, 42, tzinfo=tzutc()),\n",
       " datetime.datetime(2016, 10, 3, 22, 3, 17, tzinfo=tzutc()),\n",
       " datetime.datetime(2016, 10, 3, 22, 2, 52, tzinfo=tzutc()),\n",
       " datetime.datetime(2016, 10, 3, 14, 46, 54, tzinfo=tzutc())]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_iterator.get_timestamps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b07c36-a9f6-479f-8b26-92cd0f22786e",
   "metadata": {},
   "source": [
    "### Preprocess and download the scenes and save them as datacubes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bfab681f-e4c0-415d-bef0-23188ded8c81",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a (narrow) time window (in this case of 1 minute) within which subsequent scenes can be joined into the same mosaic\n",
    "max_time_difference_for_mosaicing = timedelta(seconds=60)\n",
    "\n",
    "for scene_id, scene_timestamp in zip(search_iterator.get_ids(), search_iterator.get_timestamps()):\n",
    "\n",
    "    # get the polarisation mode and orbit type from the scene metadata\n",
    "    polarisation = sh_catalog.get_feature(sh.DataCollection.SENTINEL1, scene_id)[\"properties\"][\"s1:polarization\"]\n",
    "    orbit = sh_catalog.get_feature(sh.DataCollection.SENTINEL1, scene_id)[\"properties\"][\"sat:orbit_state\"]\n",
    "\n",
    "    # set the directory where to download the data and the name of the zarr file that will be created\n",
    "    scene_download_directory = download_directory / orbit / f\"{polarisation.lower()}_data\" / time_period_label / f\"{scene_timestamp.strftime('%Y%m%dT%H%M%S')}\"\n",
    "    zarr_output_file_path = download_directory / orbit / f\"{polarisation.lower()}_data\" / time_period_label / f\"{scene_id}.zarr\"\n",
    "\n",
    "    # if a scene is DH don't make any request\n",
    "    if polarisation == \"DH\":\n",
    "        continue\n",
    "\n",
    "    # now we can expect that all the scenes will be SH\n",
    "    assert polarisation == \"SH\"\n",
    "    request = sh.SentinelHubRequest(\n",
    "        evalscript=evalscript_s1_pol_sh,\n",
    "        input_data=[\n",
    "            sh.SentinelHubRequest.input_data(\n",
    "                data_collection=sh.DataCollection.SENTINEL1,\n",
    "                time_interval=(\n",
    "                    scene_timestamp - max_time_difference_for_mosaicing,\n",
    "                    scene_timestamp + max_time_difference_for_mosaicing),\n",
    "                other_args={\"processing\": {\n",
    "                    \"orthorectify\": True,\n",
    "                    \"demInstance\": \"COPERNICUS\",\n",
    "                    \"backCoeff\": \"GAMMA0_TERRAIN\"}}\n",
    "            )\n",
    "        ],\n",
    "        responses=[sh.SentinelHubRequest.output_response(\"default\", sh.MimeType.TIFF)],\n",
    "        bbox=iceshelf_bbox,\n",
    "        size=(imagery_width, imagery_height),\n",
    "        config=sh_config,\n",
    "        data_folder=scene_download_directory.as_posix(),\n",
    "    )\n",
    "\n",
    "    # download the scene and save into a datacube\n",
    "    downloaded_data = sh.SentinelHubDownloadClient(config=sh_config).download(request.download_list, max_threads=1)\n",
    "    tiff_path = scene_download_directory / request.get_filename_list()[0]\n",
    "    tiff_file = xr.open_mfdataset(tiff_path, engine=\"rasterio\")\n",
    "    imagery_datacube = tiff_file.isel(band=0).drop_vars(\"band\").expand_dims(\n",
    "        dim={\"time\": [int(scene_timestamp.timestamp())]},\n",
    "        axis=0, create_index_for_new_dim=True)\n",
    "    imagery_datacube = imagery_datacube.reindex(y=imagery_datacube.y[::-1])\n",
    "    imagery_datacube = imagery_datacube.rename({\"band_data\": \"s1_imagery\"})\n",
    "    imagery_datacube = imagery_datacube.chunk(dict(time=1, x=128, y=128))\n",
    "    imagery_datacube.to_zarr(zarr_output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf2c28a-e8af-4c8e-ae61-b3272fb3620d",
   "metadata": {},
   "source": [
    "<b>Combine the data cubes and save them to S3 storage</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e429763-7bde-46d0-a535-c6b31d75ae6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/conda/deepesdl/b1713238edc260f848ded763d46a765b1625abc7984a5240701aaa391923b034-20240516-131736-043804-461-ml-2024.05/lib/python3.10/site-packages/xarray/backends/plugins.py:159: RuntimeWarning: 'netcdf4' fails while guessing\n",
      "  warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n",
      "/home/conda/deepesdl/b1713238edc260f848ded763d46a765b1625abc7984a5240701aaa391923b034-20240516-131736-043804-461-ml-2024.05/lib/python3.10/site-packages/xarray/backends/plugins.py:159: RuntimeWarning: 'h5netcdf' fails while guessing\n",
      "  warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n",
      "/home/conda/deepesdl/b1713238edc260f848ded763d46a765b1625abc7984a5240701aaa391923b034-20240516-131736-043804-461-ml-2024.05/lib/python3.10/site-packages/xarray/backends/plugins.py:159: RuntimeWarning: 'scipy' fails while guessing\n",
      "  warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'datacubes/amery/s1_imagery_res_500m_SH_HH_Ascending_2016_Q4.zarr'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orbit_type = \"ascending\"\n",
    "polarization_mode = \"SH\"\n",
    "polarization_type = \"HH\"\n",
    "time_period = \"2016_Q4\"\n",
    "data_folder = iceshelf_directory / orbit_type / f\"{polarization_mode.lower()}_data\" / time_period\n",
    "tiles_list = list(data_folder.glob(\"*.zarr\"))\n",
    "tiles_list.sort(key=os.path.getmtime, reverse=True)\n",
    "imagery_datacube = xr.open_mfdataset(\n",
    "    tiles_list, drop_variables=[\"spatial_ref\"])\n",
    "\n",
    "del imagery_datacube.s1_imagery.attrs[\"AREA_OR_POINT\"]\n",
    "del imagery_datacube.s1_imagery.attrs[\"TIFFTAG_RESOLUTIONUNIT\"]\n",
    "del imagery_datacube.s1_imagery.attrs[\"TIFFTAG_XRESOLUTION\"]\n",
    "del imagery_datacube.s1_imagery.attrs[\"TIFFTAG_YRESOLUTION\"]\n",
    "del imagery_datacube.s1_imagery.attrs[\"grid_mapping\"]\n",
    "imagery_datacube[\"s1_imagery\"].attrs = {\n",
    "    \"description\": \"Imagery tiles\",\n",
    "    \"units\": \"Normalised backscatter (linear power).\"}\n",
    "imagery_datacube = imagery_datacube.rio.write_crs(\"epsg:3031\", grid_mapping_name=\"crs\")\n",
    "imagery_datacube = imagery_datacube.assign_attrs(\n",
    "    description=f\"Sentinel-1 imagery over Amery Ice Shelf for the period {time_period.replace(\"_\", \" \")}. \\\n",
    "Polarization mode: {polarization_mode}. Polarization: {polarization_type}. Orbit: {orbit_type}.\")\n",
    "\n",
    "storage_path = f\"datacubes/{iceshelf_name}/s1_imagery_res_500m_{polarization_mode}_{polarization_type}_{orbit_type.capitalize()}_{time_period}.zarr\"\n",
    "team_store.write_data(\n",
    "    imagery_datacube, storage_path, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90045f18-2951-433b-9d32-256bca125e72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/conda/deepesdl/b1713238edc260f848ded763d46a765b1625abc7984a5240701aaa391923b034-20240516-131736-043804-461-ml-2024.05/lib/python3.10/site-packages/xarray/backends/plugins.py:159: RuntimeWarning: 'netcdf4' fails while guessing\n",
      "  warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n",
      "/home/conda/deepesdl/b1713238edc260f848ded763d46a765b1625abc7984a5240701aaa391923b034-20240516-131736-043804-461-ml-2024.05/lib/python3.10/site-packages/xarray/backends/plugins.py:159: RuntimeWarning: 'h5netcdf' fails while guessing\n",
      "  warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n",
      "/home/conda/deepesdl/b1713238edc260f848ded763d46a765b1625abc7984a5240701aaa391923b034-20240516-131736-043804-461-ml-2024.05/lib/python3.10/site-packages/xarray/backends/plugins.py:159: RuntimeWarning: 'scipy' fails while guessing\n",
      "  warnings.warn(f\"{engine!r} fails while guessing\", RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'datacubes/amery/s1_imagery_res_500m_SH_HH_Descending_2016_Q4.zarr'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orbit_type = \"descending\"\n",
    "polarization_mode = \"SH\"\n",
    "polarization_type = \"HH\"\n",
    "time_period = \"2016_Q4\"\n",
    "data_folder = iceshelf_directory / orbit_type / f\"{polarization_mode.lower()}_data\" / time_period\n",
    "tiles_list = list(data_folder.glob(\"*.zarr\"))\n",
    "tiles_list.sort(key=os.path.getmtime, reverse=True)\n",
    "imagery_datacube = xr.open_mfdataset(\n",
    "    tiles_list, drop_variables=[\"spatial_ref\"])\n",
    "\n",
    "del imagery_datacube.s1_imagery.attrs[\"AREA_OR_POINT\"]\n",
    "del imagery_datacube.s1_imagery.attrs[\"TIFFTAG_RESOLUTIONUNIT\"]\n",
    "del imagery_datacube.s1_imagery.attrs[\"TIFFTAG_XRESOLUTION\"]\n",
    "del imagery_datacube.s1_imagery.attrs[\"TIFFTAG_YRESOLUTION\"]\n",
    "del imagery_datacube.s1_imagery.attrs[\"grid_mapping\"]\n",
    "imagery_datacube[\"s1_imagery\"].attrs = {\n",
    "    \"description\": \"Imagery tiles\",\n",
    "    \"units\": \"Normalised backscatter (linear power).\"}\n",
    "imagery_datacube = imagery_datacube.rio.write_crs(\"epsg:3031\", grid_mapping_name=\"crs\")\n",
    "imagery_datacube = imagery_datacube.assign_attrs(\n",
    "    description=f\"Sentinel-1 imagery over Amery Ice Shelf for the period {time_period.replace(\"_\", \" \")}. \\\n",
    "Polarization mode: {polarization_mode}. Polarization: {polarization_type}. Orbit: {orbit_type}.\")\n",
    "\n",
    "storage_path = f\"datacubes/{iceshelf_name}/s1_imagery_res_500m_{polarization_mode}_{polarization_type}_{orbit_type.capitalize()}_{time_period}.zarr\"\n",
    "team_store.write_data(\n",
    "    imagery_datacube, storage_path, replace=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "users-deepesdl-deep-code",
   "language": "python",
   "name": "conda-env-users-deepesdl-deep-code-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
